"""
FINAL FIX - Train model with proper preprocessing + confidence calibration
Implements all 6 steps from the correction plan

Steps:
1. ‚úÖ Force same preprocessing (locked librosa settings)
2. ‚úÖ Use Mel Spectrogram with locked parameters
3. ‚úÖ Fix label mapping (HUMAN=0, AI=1)
4. ‚úÖ Change threshold to 0.65 (from 0.5)
5. ‚úÖ Add clean human voice samples
6. ‚úÖ Add spectral flatness safety override
"""

import os
import sys
import numpy as np
import pickle
import glob
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend'))

from audio_processor_fixed import AudioProcessorFixed
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score


class FinalModelFixer:
    """
    STEP 1-3: Fix preprocessing + label mapping
    STEP 4-6: Fix threshold + add safety logic
    """
    
    def __init__(self):
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.data_dir = os.path.join(self.base_dir, 'data', 'train')
        self.output_dir = os.path.join(self.base_dir, 'backend', 'models')
        
        # ‚úÖ LOCKED SETTINGS (matching audio_processor_fixed.py)
        self.audio_processor = AudioProcessorFixed()
        
        os.makedirs(self.output_dir, exist_ok=True)
    
    def load_audio_folder(self, folder_path, label, label_name):
        """
        Load all audio files from folder with CONSISTENT preprocessing
        """
        X = []
        y = []
        
        print(f"\nüìÇ Loading {label_name.upper()} voices from: {folder_path}")
        
        if not os.path.exists(folder_path):
            print(f"   ‚ö†Ô∏è  Folder not found")
            return X, y
        
        # Get all audio files (wav, mp3, etc)
        audio_patterns = ['*.wav', '*.mp3', '*.m4a', '*.flac']
        audio_files = []
        
        for pattern in audio_patterns:
            audio_files.extend(glob.glob(os.path.join(folder_path, pattern)))
        
        print(f"   Found {len(audio_files)} files")
        
        for filepath in audio_files:
            try:
                # ‚úÖ STEP 1: Consistent loading + preprocessing
                with open(filepath, 'rb') as f:
                    audio_bytes = f.read()
                
                features = self.audio_processor.extract_features(audio_bytes)
                
                if features is not None:
                    # Convert dict to ordered array (CRITICAL for consistency)
                    feature_array = np.array([features[k] for k in sorted(features.keys())])
                    X.append(feature_array)
                    y.append(label)  # ‚úÖ STEP 3: Correct label mapping
                    
                    if len(X) % 10 == 0:
                        print(f"   ‚úì Loaded {len(X)} {label_name} samples")
            
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Failed to load {filepath}: {e}")
                continue
        
        print(f"   ‚úÖ Total {label_name}: {len(X)} samples")
        return X, y
    
    def train_model(self, X_train, y_train):
        """
        Train Random Forest with optimal parameters
        """
        print("\n" + "="*70)
        print("ü§ñ TRAINING MODEL WITH FIXED PREPROCESSING")
        print("="*70)
        
        model = RandomForestClassifier(
            n_estimators=300,
            max_depth=20,
            min_samples_split=3,
            random_state=42,
            n_jobs=-1,
            class_weight='balanced'  # ‚úÖ Better for imbalanced datasets
        )
        
        print("\nTraining Random Forest...")
        model.fit(X_train, y_train)
        
        return model
    
    def evaluate_model(self, model, X_test, y_test):
        """
        Evaluate model with detailed metrics
        """
        print("\n" + "="*70)
        print("üìä MODEL EVALUATION")
        print("="*70)
        
        # Predictions
        y_pred = model.predict(X_test)
        
        # Accuracy
        accuracy = accuracy_score(y_test, y_pred)
        print(f"\n‚úÖ Test Accuracy: {accuracy*100:.2f}%")
        
        # Confusion matrix
        cm = confusion_matrix(y_test, y_pred)
        print(f"\nConfusion Matrix:")
        
        # Handle case where only one class is present
        if cm.shape == (1, 1):
            print(f"  Only one class in test set. Shape: {cm.shape}")
            print(f"  All {len(y_test)} samples correctly classified as class {y_test[0]}")
        else:
            print(f"  {cm[0][0]} Human‚ÜíHuman     {cm[0][1]} Human‚ÜíAI")
            print(f"  {cm[1][0]} AI‚ÜíHuman      {cm[1][1]} AI‚ÜíAI")
            
            # Detection rates
            human_correct = cm[0][0] / (cm[0][0] + cm[0][1])
            ai_correct = cm[1][1] / (cm[1][0] + cm[1][1])
            
            print(f"\nHuman Detection Rate: {human_correct*100:.2f}%")
            print(f"AI Detection Rate: {ai_correct*100:.2f}%")
        
        # Detailed report
        print("\nDetailed Classification Report:")
        print(classification_report(y_test, y_pred, target_names=['HUMAN', 'AI']))
        
        return accuracy
    
    def save_model(self, model, scaler, feature_names):
        """
        Save model with metadata for inference
        """
        model_path = os.path.join(self.output_dir, 'voice_detection_model.pkl')
        scaler_path = os.path.join(self.output_dir, 'voice_detection_scaler.pkl')
        
        # Save model with metadata
        model_data = {
            'model': model,
            'feature_names': feature_names,
            'label_map': {0: 'HUMAN', 1: 'AI_GENERATED'},  # ‚úÖ STEP 3: Label mapping
            'threshold': 0.65,  # ‚úÖ STEP 4: New threshold
            'spectral_flatness_threshold': 0.02  # ‚úÖ STEP 6: Safety threshold
        }
        
        with open(model_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        # Save scaler
        with open(scaler_path, 'wb') as f:
            pickle.dump(scaler, f)
        
        print(f"\nüíæ Model saved: {model_path}")
        print(f"üíæ Scaler saved: {scaler_path}")
    
    def run_full_training(self):
        """
        ‚úÖ STEPS 1-6: Complete training pipeline
        """
        print("\n" + "="*70)
        print("üî¥ FINAL MODEL FIX - ALL 6 STEPS")
        print("="*70)
        
        # ‚úÖ STEP 5: Load clean human voice data
        print("\nüì• LOADING TRAINING DATA")
        
        # Human voices (from language subdirectories)
        X_human, y_human = [], []
        human_base = os.path.join(self.data_dir, 'human')
        
        # Load from all language subdirectories
        if os.path.exists(human_base):
            for lang_dir in glob.glob(os.path.join(human_base, '*')):
                if os.path.isdir(lang_dir):
                    x_temp, y_temp = self.load_audio_folder(lang_dir, 0, f'HUMAN ({os.path.basename(lang_dir)})')
                    X_human.extend(x_temp)
                    y_human.extend(y_temp)
        
        # AI voices (multiple languages)
        X_ai, y_ai = [], []
        ai_dirs = [
            os.path.join(self.data_dir, 'ai_generated', 'english'),
            os.path.join(self.data_dir, 'ai_generated', 'hindi'),
            os.path.join(self.data_dir, 'ai_generated', 'tamil'),
            os.path.join(self.data_dir, 'ai_generated', 'telugu'),
            os.path.join(self.data_dir, 'ai_generated'),  # Fallback
        ]
        
        for ai_dir in ai_dirs:
            if os.path.exists(ai_dir):
                x_temp, y_temp = self.load_audio_folder(ai_dir, 1, 'AI')
                X_ai.extend(x_temp)
                y_ai.extend(y_temp)
        
        # Combine
        X = np.array(X_human + X_ai)
        y = np.array(y_human + y_ai)
        
        if len(X) == 0:
            print("‚ùå No training data found!")
            return
        
        print(f"\nüìä DATASET SUMMARY:")
        print(f"   Total samples: {len(X)}")
        print(f"   Human (0): {sum(y==0)}")
        print(f"   AI (1): {sum(y==1)}")
        
        # ‚úÖ STEP 1-2: Preprocessing already done in load_audio_folder
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # ‚úÖ STEP 2: Standardize features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ‚úÖ STEP 3: Train with correct label mapping
        model = self.train_model(X_train_scaled, y_train)
        
        # Evaluate
        self.evaluate_model(model, X_test_scaled, y_test)
        
        # Save model with ‚úÖ STEP 4 (threshold) and ‚úÖ STEP 6 (safety logic)
        feature_names = sorted([f'feature_{i}' for i in range(X.shape[1])])
        self.save_model(model, scaler, feature_names)
        
        print("\n" + "="*70)
        print("‚úÖ TRAINING COMPLETE - MODEL READY FOR DEPLOYMENT")
        print("="*70)
        print("\nüìã Summary of Fixes Applied:")
        print("   ‚úÖ STEP 1: Consistent audio loading (librosa locked)")
        print("   ‚úÖ STEP 2: Mel spectrogram (settings locked)")
        print("   ‚úÖ STEP 3: Label mapping (HUMAN=0, AI=1)")
        print("   ‚úÖ STEP 4: Threshold raised to 0.65")
        print("   ‚úÖ STEP 5: Training data loaded with consistent preprocessing")
        print("   ‚úÖ STEP 6: Spectral flatness safety logic added")
        print("\nüéØ Ready to test! Use inference_fixed.py")


if __name__ == "__main__":
    fixer = FinalModelFixer()
    fixer.run_full_training()
